{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8efcfbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.stats import poisson, lognorm, weibull_min\n",
    "import torch\n",
    "import igraph as ig\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from src.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR\n",
    "from src.models.dynamicHotNet import HoT_GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc38f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "with open(PROCESSED_DATA_DIR / \"temporal_hypergraph.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "temporal_hyperedges = data['temporal_hyperedges']\n",
    "dynamic_features = data['dynamic_features']\n",
    "disaster_exposure = data['disaster_exposure']\n",
    "X_n = data['X_n']\n",
    "X_e = data['X_e']\n",
    "A_tilde = data['A_tilde']\n",
    "B1_tilde = data['B1_tilde']\n",
    "L1_tilde = data['L1_tilde']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be37469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes, n_edges, n_timesteps = 9168, 11667, 600\n",
    "F_nodes, F_edges = X_n.shape[1], X_e.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcaa2e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查维度\n",
    "assert dynamic_features.shape == (n_nodes, n_timesteps, F_nodes), f\"Expected dynamic_features shape {(n_nodes, n_timesteps, F_nodes)}, got {dynamic_features.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4f15025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 生成灾害事件\n",
    "def generate_disaster_events(n_timesteps, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    events = []\n",
    "    earthquake_rate = 0.01 * n_timesteps / (50 * 12)\n",
    "    n_earthquakes = poisson.rvs(earthquake_rate * n_timesteps)\n",
    "    earthquake_times = np.random.uniform(0, n_timesteps, n_earthquakes)\n",
    "    earthquake_magnitudes = lognorm.rvs(s=0.5, scale=np.exp(6), size=n_earthquakes)\n",
    "    flood_rate = 0.05 * n_timesteps / (50 * 12)\n",
    "    n_floods = poisson.rvs(flood_rate * n_timesteps)\n",
    "    flood_times = np.random.uniform(0, n_timesteps, n_floods)\n",
    "    flood_depths = lognorm.rvs(s=0.5, scale=np.exp(0), size=n_floods)\n",
    "    hurricane_rate = 0.02 * n_timesteps / (50 * 12)\n",
    "    n_hurricanes = poisson.rvs(hurricane_rate * n_timesteps)\n",
    "    hurricane_times = np.random.uniform(0, n_timesteps, n_hurricanes)\n",
    "    hurricane_speeds = weibull_min.rvs(c=2, scale=20, size=n_hurricanes)\n",
    "    for t, mag in zip(earthquake_times, earthquake_magnitudes):\n",
    "        events.append(('earthquake', t, mag))\n",
    "    for t, depth in zip(flood_times, flood_depths):\n",
    "        events.append(('flood', t, depth))\n",
    "    for t, speed in zip(hurricane_times, hurricane_speeds):\n",
    "        events.append(('hurricane', t, speed))\n",
    "    events.sort(key=lambda x: x[1])\n",
    "    return events\n",
    "\n",
    "disaster_events = generate_disaster_events(n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77350743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('earthquake', np.float64(12.350696577481468), np.float64(254.1586252942617)),\n",
       " ('hurricane', np.float64(15.251476046457114), np.float64(11.698552113608882)),\n",
       " ('hurricane', np.float64(18.85751141204055), np.float64(32.588035141018395)),\n",
       " ('flood', np.float64(20.633112669131037), np.float64(0.8144912006756959)),\n",
       " ('flood', np.float64(27.870247631998634), np.float64(0.5100028073451038)),\n",
       " ('flood', np.float64(39.03095579116771), np.float64(1.069524803889581)),\n",
       " ('flood', np.float64(58.60326840383032), np.float64(0.9016012362786295)),\n",
       " ('hurricane', np.float64(64.73485619598267), np.float64(8.385901466152887)),\n",
       " ('flood', np.float64(73.2229409068673), np.float64(1.7329471047237062)),\n",
       " ('flood', np.float64(83.6963163912251), np.float64(4.011465038183434)),\n",
       " ('flood', np.float64(102.31447421237492), np.float64(0.5682032144422158)),\n",
       " ('flood', np.float64(119.80426929501584), np.float64(0.4530978797419071)),\n",
       " ('flood', np.float64(155.26798896001014), np.float64(0.6381997417908131)),\n",
       " ('flood', np.float64(175.28678912113088), np.float64(1.8163334154466904)),\n",
       " ('flood', np.float64(182.7682615040224), np.float64(1.4586318372889633)),\n",
       " ('flood', np.float64(187.02664565364657), np.float64(1.1598384082297808)),\n",
       " ('hurricane', np.float64(188.613588645796), np.float64(20.03491143499797)),\n",
       " ('flood', np.float64(219.81710597621503), np.float64(1.1155183201591814)),\n",
       " ('hurricane', np.float64(256.5246110151298), np.float64(5.660539852352472)),\n",
       " ('flood', np.float64(264.0914962437608), np.float64(0.47044480191169946)),\n",
       " ('flood', np.float64(273.64199053022156), np.float64(1.5540750095500806)),\n",
       " ('hurricane', np.float64(296.27735781863447), np.float64(23.73814775873285)),\n",
       " ('flood', np.float64(297.1061460667621), np.float64(0.9149681156157683)),\n",
       " ('flood', np.float64(308.54066304816695), np.float64(1.4723359312244482)),\n",
       " ('hurricane', np.float64(313.63969762919646), np.float64(10.194217123789233)),\n",
       " ('hurricane', np.float64(336.76631854169773), np.float64(10.709599861494327)),\n",
       " ('flood', np.float64(355.4487413172255), np.float64(0.7640891326628423)),\n",
       " ('earthquake', np.float64(360.6690070459253), np.float64(310.2613777978304)),\n",
       " ('flood', np.float64(364.52691114086304), np.float64(0.6438460507899573)),\n",
       " ('hurricane', np.float64(381.84624675826825), np.float64(25.69737014158896)),\n",
       " ('flood', np.float64(397.51337061238917), np.float64(1.5180061185265468)),\n",
       " ('flood', np.float64(410.53981590729416), np.float64(0.7321728218287573)),\n",
       " ('earthquake', np.float64(424.8435466776273), np.float64(303.17491528687566)),\n",
       " ('hurricane', np.float64(427.946872333797), np.float64(16.85748708597091)),\n",
       " ('hurricane', np.float64(456.4710291701385), np.float64(30.86269936247298)),\n",
       " ('hurricane', np.float64(462.5803079727366), np.float64(14.5366017333168)),\n",
       " ('flood', np.float64(471.10557683580817), np.float64(0.6037816388883385)),\n",
       " ('flood', np.float64(485.03840886987666), np.float64(1.5638741389290258)),\n",
       " ('earthquake', np.float64(499.465584480253), np.float64(648.8391487332088)),\n",
       " ('earthquake', np.float64(519.7056874649611), np.float64(301.73855574797346)),\n",
       " ('flood', np.float64(545.5922412472693), np.float64(1.8037325781037359)),\n",
       " ('flood', np.float64(569.3313223519999), np.float64(1.3378467216806291)),\n",
       " ('flood', np.float64(579.3792198447356), np.float64(1.5587344309469513)),\n",
       " ('earthquake', np.float64(581.9459112971966), np.float64(109.25946798000697))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(disaster_events))\n",
    "disaster_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5b94d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 生成交互标签\n",
    "def generate_interaction_labels(events, disaster_exposure, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    interactions = []\n",
    "    for event in events:\n",
    "        disaster_type, t, intensity = event\n",
    "        if disaster_type == 'earthquake' and intensity > 6:\n",
    "            prob = 0.8 if intensity > 7 else 0.6\n",
    "            affected_nodes = np.where(disaster_exposure[:, 0] > np.percentile(disaster_exposure[:, 0], 90))[0]\n",
    "            interactions.append(('earthquake-liquefaction', t, prob, affected_nodes))\n",
    "        elif disaster_type == 'flood':\n",
    "            hurricane_events = [e for e in events if e[0] == 'hurricane' and abs(e[1] - t) < 1]\n",
    "            if hurricane_events:\n",
    "                prob = 0.9\n",
    "                affected_nodes = np.where(disaster_exposure[:, 1] > np.percentile(disaster_exposure[:, 1], 90))[0]\n",
    "                interactions.append(('flood-hurricane', t, prob, affected_nodes))\n",
    "    return interactions\n",
    "\n",
    "interaction_labels = generate_interaction_labels(disaster_events, disaster_exposure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad66985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 训练HoT_GNN\n",
    "model = HoT_GNN(n_nodes=9168, node_features=F_nodes, edge_features=F_edges, node_hidden=[32, 16, 8], edge_hidden=[16, 8, 1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# GPU支持（可选）\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "X_e = X_e.to(device)\n",
    "A_tilde = A_tilde.to(device)\n",
    "L1_tilde = L1_tilde.to(device)\n",
    "B1_tilde = B1_tilde.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47f52b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_timesteps):\n\u001b[32m      7\u001b[39m     X_n_t = torch.tensor(dynamic_features[:, t, :], dtype=torch.float32).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_n_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_tilde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL1_tilde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB1_tilde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemporal_hyperedges\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m outputs[\u001b[33m'\u001b[39m\u001b[33mhyperedge_prob\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m         target = [prob \u001b[38;5;28;01mfor\u001b[39;00m t_label, _, prob \u001b[38;5;129;01min\u001b[39;00m hyperedge_labels \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(t - t_label) < \u001b[32m0.5\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Work/DevSpace/PowerGridCompoundRisk/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Work/DevSpace/PowerGridCompoundRisk/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Volumes/Work/DevSpace/PowerGridCompoundRisk/src/models/dynamicHotNet.py:100\u001b[39m, in \u001b[36mHoT_GNN.forward\u001b[39m\u001b[34m(self, X_n, X_e, A_tilde, L1_tilde, B1, hyperedges)\u001b[39m\n\u001b[32m     98\u001b[39m         prob = torch.sigmoid(\u001b[38;5;28mself\u001b[39m.hyperedge_head(hyperedge_features))  \u001b[38;5;66;03m# [1]\u001b[39;00m\n\u001b[32m     99\u001b[39m         hyperedge_probs.append(prob)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m     hyperedge_prob = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyperedge_probs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [n_hyperedges]\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m     hyperedge_prob = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "hyperedge_labels = [(t, nodes, prob) for _, t, prob, nodes in interaction_labels]\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = 0\n",
    "    for t in range(n_timesteps):\n",
    "        X_n_t = torch.tensor(dynamic_features[:, t, :], dtype=torch.float32).to(device)\n",
    "        outputs = model(X_n_t, X_e, A_tilde, L1_tilde, B1_tilde, temporal_hyperedges[t])\n",
    "        if outputs['hyperedge_prob'] is not None:\n",
    "            target = [prob for t_label, _, prob in hyperedge_labels if abs(t - t_label) < 0.5]\n",
    "            if target and len(target) == len(outputs['hyperedge_prob']):\n",
    "                target = torch.tensor(target, dtype=torch.float32).to(device)\n",
    "                loss = criterion(outputs['hyperedge_prob'], target)\n",
    "                total_loss += loss\n",
    "    if total_loss > 0:\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss.item() if isinstance(total_loss, torch.Tensor) else 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776a82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 预测初始失效\n",
    "def predict_initial_failure(events, disaster_exposure, model, dynamic_features, X_e, A_tilde, B1_tilde, L1_tilde, device):\n",
    "    failure_probs = np.zeros((n_nodes, n_timesteps))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for t in range(n_timesteps):\n",
    "            X_n_t = torch.tensor(dynamic_features[:, t, :], dtype=torch.float32).to(device)\n",
    "            outputs = model(X_n_t, X_e, A_tilde, L1_tilde, B1_tilde)\n",
    "            failure_probs[:, t] = outputs['node_prob'].cpu().numpy()\n",
    "    return failure_probs\n",
    "\n",
    "initial_failure_probs = predict_initial_failure(disaster_events, disaster_exposure, model, dynamic_features, X_e, A_tilde, B1_tilde, L1_tilde, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61be0af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 更新时间超图\n",
    "def update_temporal_hypergraph(temporal_hyperedges, initial_failure_probs, interaction_labels):\n",
    "    updated_hyperedges = temporal_hyperedges.copy()\n",
    "    for t in range(n_timesteps):\n",
    "        failed_nodes = np.where(initial_failure_probs[:, t] > 0.5)[0]\n",
    "        if len(failed_nodes) > 1:\n",
    "            updated_hyperedges[t].append(failed_nodes.tolist())\n",
    "        for inter_type, inter_t, prob, nodes in interaction_labels:\n",
    "            if abs(inter_t - t) < 0.5 and prob > 0.7:\n",
    "                updated_hyperedges[t].append(nodes.tolist())\n",
    "    return updated_hyperedges\n",
    "\n",
    "updated_hyperedges = update_temporal_hypergraph(temporal_hyperedges, initial_failure_probs, interaction_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3748720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存结果\n",
    "with open(PROCESSED_DATA_DIR / \"disaster_simulation.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        'disaster_events': disaster_events,\n",
    "        'interaction_labels': interaction_labels,\n",
    "        'initial_failure_probs': initial_failure_probs,\n",
    "        'updated_hyperedges': updated_hyperedges\n",
    "    }, f)\n",
    "\n",
    "print(\"灾害模拟完成，保存至 disaster_simulation.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af071236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
