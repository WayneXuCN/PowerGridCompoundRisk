{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from scipy.integrate import odeint\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "# 设置中文字体为 Mac 系统中文字体\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"Arial Unicode MS\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 数据预处理\n",
    "# 读取网络数据\n",
    "edge_file = \"data/raw/european/powergridEU_E.csv\"\n",
    "coord_file = \"data/raw/european/powergridEU_V.csv\"\n",
    "\n",
    "# 读取数据\n",
    "edges = pd.read_csv(edge_file, header=None).values.tolist()\n",
    "coords = pd.read_csv(coord_file, header=None)  # 节点坐标数据\n",
    "\n",
    "# 创建无向图\n",
    "g = ig.Graph.TupleList(edges, directed=False)\n",
    "g.vs[\"name\"] = [int(v) for v in g.vs[\"name\"]]  # 节点名转为整数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建节点ID到索引的映射以加速查找\n",
    "name_to_index = {v[\"name\"]: idx for idx, v in enumerate(g.vs)}\n",
    "# 批量添加坐标数据\n",
    "latitudes = [None] * g.vcount()\n",
    "longitudes = [None] * g.vcount()\n",
    "for _, row in coords.iterrows():\n",
    "    node_id = int(row[0])\n",
    "    if node_id in name_to_index:  # 防止数据不匹配导致的错误\n",
    "        idx = name_to_index[node_id]\n",
    "        latitudes[idx] = row[1]\n",
    "        longitudes[idx] = row[2]\n",
    "\n",
    "# 批量设置顶点属性\n",
    "g.vs[\"latitude\"] = latitudes\n",
    "g.vs[\"longitude\"] = longitudes\n",
    "\n",
    "# 检查数据完整性\n",
    "assert all(lat is not None for lat in latitudes), \"存在缺失的纬度数据\"\n",
    "assert all(lon is not None for lon in longitudes), \"存在缺失的经度数据\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向量化的 Haversine 距离计算\n",
    "def haversine_distances(lats, lons):\n",
    "    \"\"\"\n",
    "    计算所有节点对之间的 Haversine 距离（km）\n",
    "    使用向量化操作提高效率\n",
    "    \"\"\"\n",
    "    # 转换为弧度\n",
    "    lats_rad = np.radians(lats)\n",
    "    lons_rad = np.radians(lons)\n",
    "    # 使用广播计算差值\n",
    "    lat_matrix = lats_rad[:, np.newaxis] - lats_rad[np.newaxis, :]\n",
    "    lon_matrix = lons_rad[:, np.newaxis] - lons_rad[np.newaxis, :]\n",
    "    # Haversine 公式\n",
    "    a = np.sin(lat_matrix / 2) ** 2 + np.cos(lats_rad[:, np.newaxis]) * np.cos(lats_rad[np.newaxis, :]) * np.sin(\n",
    "        lon_matrix / 2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(np.clip(a, 0, 1)))  # 添加 clip 避免数值误差\n",
    "\n",
    "    # 地球半径 (km)\n",
    "    R = 6371\n",
    "    return R * c\n",
    "\n",
    "# 计算节点间地理距离矩阵（用于动态传播因子）\n",
    "distances = haversine_distances(np.array(latitudes), np.array(longitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "from scipy.sparse import coo_matrix, csr_matrix, lil_matrix\n",
    "\n",
    "# 一阶邻接矩阵 A（稀疏格式）\n",
    "edges = np.array(g.get_edgelist())\n",
    "n_nodes, n_edges = g.vcount(), len(edges)\n",
    "adj_sparse = coo_matrix((np.ones(len(edges)), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(g.vcount(), g.vcount())).tocsr()\n",
    "edge_dict = {tuple(sorted(e)): idx for idx, e in enumerate(edges)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 B1\n",
    "B1 = lil_matrix((n_nodes, n_edges)) # lil_matrix 更适合动态插入\n",
    "for idx, (i, j) in enumerate(edges):\n",
    "    B1[i, idx] = 1  # 起点+1\n",
    "    # B1[j, idx] = -1  # 终点-1\n",
    "    B1[j, idx] = 1  # 无向边：两个节点均标记为+1\n",
    "B1 = B1.tocsr()  # 转换为CSR用于后续计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测所有3节点环路\n",
    "triangles = []\n",
    "for node in g.vs:\n",
    "    neighbors = node.neighbors()\n",
    "    for pair in combinations(neighbors, 2):\n",
    "        if g.are_adjacent(pair[0], pair[1]):\n",
    "            triangle = sorted([node.index, pair[0].index, pair[1].index])\n",
    "            triangles.append(tuple(triangle))\n",
    "triangles = list(set(triangles))  # 去重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 B2（统一顺时针定向）\n",
    "B2 = lil_matrix((n_edges, len(triangles)))\n",
    "for t_idx, triangle in enumerate(triangles):\n",
    "    # 定义顺时针边顺序：A→B, B→C, C→A\n",
    "    ordered_edges = [\n",
    "        tuple(sorted((triangle[0], triangle[1]))),\n",
    "        tuple(sorted((triangle[1], triangle[2]))),\n",
    "        tuple(sorted((triangle[2], triangle[0])))\n",
    "    ]\n",
    "    for i, edge in enumerate(ordered_edges):\n",
    "        if edge in edge_dict:\n",
    "            B2[edge_dict[edge], t_idx] = 1 if i == 0 else -1\n",
    "B2 = B2.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 Hodge Laplacian\n",
    "L1 = B1.T @ B1 + B2 @ B2.T\n",
    "\n",
    "# 正确归一化（处理空矩阵）\n",
    "B2_squared = B2 @ B2.T\n",
    "if B2_squared.ndim == 0:\n",
    "    D1_diag = np.zeros(n_edges)  # 无三角形时度数为0\n",
    "else:\n",
    "    # 代码中通过 B2_squared.sum(axis=1) 计算 D1_diag，这实际是每行元素的总和 ，而非每个边的度数（即边参与的三角形数量）\n",
    "    # D1_diag = np.array(B2_squared.sum(axis=1)).flatten()  # 显式转换为密集数组\n",
    "    D1_diag = B2_squared.diagonal()  # 修正后的代码：提取对角线元素\n",
    "    D1_diag = np.maximum(D1_diag, 0)  # 强制非负，避免负值\n",
    "# 避免除零错误（添加1e-6偏移量）\n",
    "D1_diag_safe = D1_diag + 1e-6\n",
    "D1_inv_sqrt = csr_matrix(np.diag(1.0 / np.sqrt(D1_diag_safe)))  # 计算平方根倒数\n",
    "L1_tilde = D1_inv_sqrt @ L1 @ D1_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B1.shape, B2.shape, L1.shape, L1_tilde.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"检测到 {len(triangles)} 个三角形环路\")\n",
    "print(f\"B2 shape: {B2.shape}\")\n",
    "print(f\"B2_squared shape: {B2_squared.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClimateParams:\n",
    "    flood_max_lat = 55      # 洪水风险最大纬度\n",
    "    flood_scale = 10        # 洪水风险衰减系数\n",
    "    heat_min_lat = 40       # 热浪风险最小纬度\n",
    "    heat_scale = 15         # 热浪风险增长系数\n",
    "    drought_offset = 10     # 干旱经度偏移量\n",
    "    drought_scale = 20      # 干旱风险缩放系数\n",
    "\n",
    "latitudes = np.array(g.vs[\"latitude\"], dtype=np.float32)\n",
    "longitudes = np.array(g.vs[\"longitude\"], dtype=np.float32)\n",
    "# 洪水风险：纬度越低风险越高\n",
    "F = np.maximum(0, (ClimateParams.flood_max_lat - latitudes) / ClimateParams.flood_scale)\n",
    "# 热浪风险：纬度越高风险越高\n",
    "H = np.maximum(0, (latitudes - ClimateParams.heat_min_lat) / ClimateParams.heat_scale)\n",
    "# 干旱风险：经度越东风险越高\n",
    "D = np.maximum(0, (longitudes + ClimateParams.drought_offset) / ClimateParams.drought_scale)\n",
    "\"\"\"\n",
    "# 归一化风险值到 [0, 1] 范围\n",
    "scaler = MinMaxScaler()\n",
    "F = scaler.fit_transform(F.reshape(-1, 1)).flatten()\n",
    "H = scaler.fit_transform(H.reshape(-1, 1)).flatten()\n",
    "D = scaler.fit_transform(D.reshape(-1, 1)).flatten()\n",
    "\"\"\"\n",
    "X_feature = np.column_stack([latitudes, longitudes, F, H, D])\n",
    "print(f\"气候特征生成完成，形状：{X_feature.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.array(g.get_edgelist())  # 边列表 (16922×2)\n",
    "print(edges.shape)\n",
    "edge_features = []\n",
    "for idx, (i, j) in enumerate(edges):\n",
    "    # 节点特征拼接\n",
    "    node_features = np.concatenate([X_feature[i], X_feature[j]])\n",
    "    # 边的距离（仅相邻节点）\n",
    "    distance = distances[i, j]\n",
    "    # 合并为边特征\n",
    "    edge_feature = np.hstack([node_features, distance])\n",
    "    edge_features.append(edge_feature)\n",
    "edge_features = np.array(edge_features, dtype=np.float32)\n",
    "print(f\"边特征生成完成，形状：{edge_features.shape}（应为 16922×11）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. 高阶图神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.functional import relu, sigmoid\n",
    "\n",
    "class HoSC(nn.Module):\n",
    "    \"\"\"HodgeSimplexConv\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, L1_tilde):\n",
    "        super(HoSC, self).__init__()\n",
    "        self.L1_tilde = L1_tilde  # 归一化Hodge Laplacian (稀疏矩阵)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, Z):\n",
    "        # 将边特征转换为PyTorch稀疏张量\n",
    "        Z = torch.FloatTensor(Z).unsqueeze(-1)  # (n_edges, input_dim, 1)\n",
    "\n",
    "        # 第一层单纯形卷积\n",
    "        Z1 = self.L1_tilde @ Z  # 使用稀疏矩阵乘法\n",
    "        Z1 = self.fc1(Z1.squeeze(-1))\n",
    "        Z1 = relu(Z1)\n",
    "\n",
    "        # 第二层单纯形卷积\n",
    "        Z2 = self.L1_tilde @ Z1.unsqueeze(-1)\n",
    "        Z2 = self.fc2(Z2.squeeze(-1))\n",
    "\n",
    "        return Z2  # 输出边级嵌入 (n_edges, output_dim)\n",
    "\n",
    "\n",
    "class NodeFailurePredictor(nn.Module):\n",
    "    def __init__(self, hoc_model, B1_abs):\n",
    "        super(NodeFailurePredictor, self).__init__()\n",
    "        self.hoc_model = hoc_model\n",
    "        self.B1_abs = B1_abs  # 边界矩阵的绝对值（稀疏矩阵）\n",
    "\n",
    "    def forward(self, Z_edge):\n",
    "        # 计算节点失效概率\n",
    "        edge_embeddings = self.hoc_model(Z_edge)  # (n_edges, output_dim)\n",
    "        node_logits = self.B1_abs.T @ edge_embeddings  # (n_nodes, output_dim)\n",
    "        node_prob = sigmoid(node_logits.sum(axis=1))  # 聚合边特征并压缩到[0,1]\n",
    "        return node_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_edge_features(disaster_type, distances, edges, F, H, D):\n",
    "    \"\"\"根据灾害类型生成边特征\"\"\"\n",
    "    n_edges = len(edges)\n",
    "    edge_features = []\n",
    "\n",
    "    if disaster_type == \"flood\":\n",
    "        risk_coupling = F\n",
    "    elif disaster_type == \"heatwave\":\n",
    "        risk_coupling = H\n",
    "    elif disaster_type == \"drought\":\n",
    "        risk_coupling = D\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported disaster type\")\n",
    "\n",
    "    # 构建边特征矩阵\n",
    "    for u, v in edges:\n",
    "        distance = distances[u, v]\n",
    "        risk_sum = risk_coupling[u] + risk_coupling[v]\n",
    "        edge_features.append([distance, risk_sum])\n",
    "\n",
    "    return np.array(edge_features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "input_dim = 2  # 地理距离 + 灾害风险\n",
    "hidden_dim = 16\n",
    "output_dim = 8\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-4\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理：将B1转换为绝对值稀疏矩阵\n",
    "B1_abs = abs(B1).tocsr()\n",
    "\n",
    "# 初始化模型\n",
    "hoc_model = HoSC(input_dim, hidden_dim, output_dim, L1_tilde)\n",
    "predictor = NodeFailurePredictor(hoc_model, abs(B1).tocsr())\n",
    "optimizer = optim.Adam(predictor.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练数据（以洪水为例）\n",
    "def train(disaster_type):\n",
    "    edge_features = generate_edge_features(disaster_type, distances, edges, F, H, D)\n",
    "\n",
    "    # 创建标签（假设纬度<45的节点中10%失效）\n",
    "    labels = np.zeros(len(g.vs))\n",
    "    southern_nodes = np.where(latitudes < 45)[0]\n",
    "    failed_nodes = np.random.choice(southern_nodes, size=int(0.1*len(southern_nodes)), replace=False)\n",
    "    labels[failed_nodes] = 1\n",
    "    labels = torch.FloatTensor(labels)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        prob = predictor(torch.FloatTensor(edge_features))\n",
    "        loss = criterion(prob, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# 运行训练\n",
    "train(\"flood\") # 或 \"heatwave\", \"drought\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
