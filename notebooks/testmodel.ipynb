{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "\n",
    "# 假设LOGS_DIR已定义\n",
    "LOGS_DIR = Path(\"logs\")\n",
    "\n",
    "# HoSC 单层模块：高阶单纯形卷积\n",
    "class HigherOrderSimplicialConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.theta = nn.Linear(in_channels, out_channels)\n",
    "        self.bn = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, Z_H, L1_tilde):\n",
    "        Z_theta = self.theta(Z_H)\n",
    "        Z_conv = torch.sparse.mm(L1_tilde, Z_theta) if L1_tilde.is_sparse else torch.mm(L1_tilde, Z_theta)\n",
    "        Z_psi = F.relu(self.bn(Z_conv))\n",
    "        Z_max, _ = torch.max(Z_psi, dim=1, keepdim=True)\n",
    "        return Z_max\n",
    "\n",
    "# HoSC 模块：多层高阶单纯形卷积\n",
    "class HoSC(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        current_dim = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            self.layers.append(HigherOrderSimplicialConv(current_dim, dim))\n",
    "            current_dim = 1\n",
    "\n",
    "    def forward(self, edge_attr, L1_tilde):\n",
    "        Z_list = []\n",
    "        Z_H = edge_attr\n",
    "        for layer in self.layers:\n",
    "            Z_H = layer(Z_H, L1_tilde)\n",
    "            Z_list.append(Z_H)\n",
    "        return torch.cat(Z_list, dim=1)\n",
    "\n",
    "# GNN 模块：节点特征提取\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        current_dim = input_dim\n",
    "        for dim in hidden_dims:\n",
    "            self.layers.append(nn.Linear(current_dim, dim))\n",
    "            current_dim = dim\n",
    "\n",
    "    def forward(self, X_n, A_tilde):\n",
    "        H = X_n\n",
    "        for layer in self.layers:\n",
    "            H = torch.mm(A_tilde, H)\n",
    "            H = F.relu(H @ layer.weight.T + layer.bias)\n",
    "        return H\n",
    "\n",
    "# HoT_GNN：多任务高阶拓扑GNN\n",
    "class HoT_GNN(nn.Module):\n",
    "    def __init__(self, n_nodes, node_features, edge_features, node_hidden, edge_hidden):\n",
    "        super().__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.gnn = GNN(node_features, node_hidden)  # 节点特征提取\n",
    "        self.hosc = HoSC(edge_features, edge_hidden)  # 边特征与高阶拓扑提取\n",
    "        \n",
    "        # 输出头\n",
    "        self.node_head = nn.Linear(node_hidden[-1] + len(edge_hidden), 1)  # 节点失效概率\n",
    "        self.edge_head = nn.Linear(len(edge_hidden), 1)  # 边失效概率\n",
    "        self.hyperedge_head = nn.Linear(node_hidden[-1] + len(edge_hidden), 1)  # 超边交互概率\n",
    "        \n",
    "        # 嵌入维度\n",
    "        self.embed_dim = node_hidden[-1] + len(edge_hidden)\n",
    "\n",
    "    def forward(self, X_n, X_e, A_tilde, L1_tilde, B1, hyperedges=None):\n",
    "        # 节点特征提取\n",
    "        H_n = self.gnn(X_n, A_tilde)  # [n, d_{L_n}]\n",
    "\n",
    "        # 边特征与高阶拓扑提取\n",
    "        Z_H = self.hosc(X_e, L1_tilde)  # [M, L_e]\n",
    "\n",
    "        # 边到节点映射\n",
    "        H_e = torch.sparse.mm(B1, Z_H) if B1.is_sparse else torch.mm(B1, Z_H)  # [n, L_e]\n",
    "\n",
    "        # 特征融合\n",
    "        H = torch.cat([H_n, H_e], dim=1)  # [n, d_{L_n} + L_e]\n",
    "\n",
    "        # 节点失效概率\n",
    "        node_prob = torch.sigmoid(self.node_head(H)).squeeze(-1)  # [n]\n",
    "\n",
    "        # 边失效概率\n",
    "        edge_prob = torch.sigmoid(self.edge_head(Z_H)).squeeze(-1)  # [M]\n",
    "\n",
    "        # 超边交互概率\n",
    "        if hyperedges is not None:\n",
    "            hyperedge_probs = []\n",
    "            for hyperedge in hyperedges:\n",
    "                # 聚合超边内节点特征\n",
    "                hyperedge_features = H[hyperedge].mean(dim=0)  # [d_{L_n} + L_e]\n",
    "                prob = torch.sigmoid(self.hyperedge_head(hyperedge_features))  # [1]\n",
    "                hyperedge_probs.append(prob)\n",
    "            hyperedge_prob = torch.stack(hyperedge_probs)  # [n_hyperedges]\n",
    "        else:\n",
    "            hyperedge_prob = None\n",
    "\n",
    "        return {\n",
    "            'node_prob': node_prob,  # [9168]\n",
    "            'edge_prob': edge_prob,  # [11667]\n",
    "            'hyperedge_prob': hyperedge_prob,  # [n_hyperedges] or None\n",
    "            'node_embedding': H  # [9168, d_{L_n} + L_e]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, M = 9168, 11667\n",
    "X_n = torch.randn(n, 23)\n",
    "X_e = torch.randn(M, 17)\n",
    "A_tilde = torch.randn(n, n)\n",
    "L1_tilde = torch.randn(M, M)\n",
    "B1 = torch.randn(n, M)\n",
    "hyperedges = [[0, 1, 2], [3, 4, 5]]  # 示例超边"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型初始化\n",
    "model = HoT_GNN(\n",
    "    n_nodes=n,\n",
    "    node_features=23,\n",
    "    edge_features=17,\n",
    "    node_hidden=[32, 16, 8],\n",
    "    edge_hidden=[16, 8, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node prob shape: torch.Size([9168])\n",
      "Edge prob shape: torch.Size([11667])\n",
      "Hyperedge prob shape: torch.Size([2, 1])\n",
      "Node embedding shape: torch.Size([9168, 11])\n"
     ]
    }
   ],
   "source": [
    "# 前向传播\n",
    "outputs = model(X_n, X_e, A_tilde, L1_tilde, B1, hyperedges)\n",
    "print(f\"Node prob shape: {outputs['node_prob'].shape}\")  # [1000]\n",
    "print(f\"Edge prob shape: {outputs['edge_prob'].shape}\")  # [1500]\n",
    "print(f\"Hyperedge prob shape: {outputs['hyperedge_prob'].shape}\")  # [2]\n",
    "print(f\"Node embedding shape: {outputs['node_embedding'].shape}\")  # [1000, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================================================================================================\n",
      "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #\n",
      "=============================================================================================================================\n",
      "HoT_GNN                                            [9168, 23]                [9168, 11]                --\n",
      "├─GNN: 1-1                                         [9168, 23]                [9168, 8]                 1,432\n",
      "├─HoSC: 1-2                                        [11667, 17]               [11667, 3]                --\n",
      "│    └─ModuleList: 2-1                             --                        --                        --\n",
      "│    │    └─HigherOrderSimplicialConv: 3-1         [11667, 17]               [11667, 1]                --\n",
      "│    │    │    └─Linear: 4-1                       [11667, 17]               [11667, 16]               288\n",
      "│    │    │    └─BatchNorm1d: 4-2                  [11667, 16]               [11667, 16]               32\n",
      "│    │    └─HigherOrderSimplicialConv: 3-2         [11667, 1]                [11667, 1]                --\n",
      "│    │    │    └─Linear: 4-3                       [11667, 1]                [11667, 8]                16\n",
      "│    │    │    └─BatchNorm1d: 4-4                  [11667, 8]                [11667, 8]                16\n",
      "│    │    └─HigherOrderSimplicialConv: 3-3         [11667, 1]                [11667, 1]                --\n",
      "│    │    │    └─Linear: 4-5                       [11667, 1]                [11667, 1]                2\n",
      "│    │    │    └─BatchNorm1d: 4-6                  [11667, 1]                [11667, 1]                2\n",
      "├─Linear: 1-3                                      [9168, 11]                [9168, 1]                 12\n",
      "├─Linear: 1-4                                      [11667, 3]                [11667, 1]                4\n",
      "├─Linear: 1-5                                      [11]                      [1]                       12\n",
      "├─Linear: 1-6                                      [11]                      [1]                       (recursive)\n",
      "=============================================================================================================================\n",
      "Total params: 1,816\n",
      "Trainable params: 1,816\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 4.31\n",
      "=============================================================================================================================\n",
      "Input size (MB): 1310.17\n",
      "Forward/backward pass size (MB): 4.83\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 1315.01\n",
      "=============================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(model,input_data=(X_n, X_e, A_tilde, L1_tilde, B1, hyperedges),depth=4,col_names=[\"input_size\", \"output_size\", \"num_params\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
